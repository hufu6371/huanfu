
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="refresh" content="0; URL=https://huan-fu.github.io/">
    <title>Your Page Title</title>
    <!-- Your existing meta tags, styles, and other head elements go here -->
</head>
<body>
    <!-- Your existing body content goes here -->
</body>
</html>


<a href="#aboutme" style="color:black; font-family:fantasy; font-size: 100%;">**About**</a> &nbsp; &nbsp; &nbsp; <a href="#updates" style="color:coral; font-family:fantasy; font-size: 100%;">**Updates**</a> &nbsp; &nbsp; &nbsp; <a href="#publication" style="color:coral; font-family:fantasy; font-size: 100%;">**Publications**</a> &nbsp; &nbsp; &nbsp; <a href="#experience" style="color:coral; font-family:fantasy; font-size: 100%;">**Experience**</a> &nbsp; &nbsp; &nbsp; <a href="#service" style="color:coral; font-family:fantasy; font-size: 100%;">**Services**</a>

---

<a name="aboutme"></a>
<img align="left" width="200" height="255" src="photo/huanfu_photo.JPG" style="padding-right: 20px">

Greetings! I am <tt style="color:Tomato; font-size: 100%;">**Fu, Huan (付欢)**</tt>. I am currently a Staff Algorithm Engineer in Tao Technology Department, Alibaba Group. I obtained my Ph.D. degree from University of Sydney (USYD) in April 2019. Thanks to the continuous guidance, support and encoragement of my supervisor [**Prof. Dacheng Tao**](https://scholar.google.com/citations?user=RwlJNLcAAAAJ&hl=en), and co-supervisors [**A/Prof. Chaohui Wang**](http://igm.univ-mlv.fr/~cwang/index.php) and [**A/Prof. Mingming Gong**](https://mingming-gong.github.io/). Piror to that, I got my bachelor degree from University of Science and Technology of China (USTC) in July 2014.

**Research:** Computer Vision (Semantic Segmentation, Depth Estimation, and Boundary Detection *etc.*), Domain Adapation, Generative Adversarial Network, 3D Vision.

**[New Homepage](https://huan-fu.github.io/)** &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; **[Google Scholar](https://scholar.google.com/citations?hl=en&user=EYTzVMwAAAAJ)**

---

<a name="updates"></a>
### Updates
- 10/2023, Welcome to join our [3D Vision and Modeling Challenges in eCommerce
ICCV 2023 Workshop](https://3dv-in-ecommerce.github.io/).
- 06/2023, One paper has been accepted to ICCV23.
- 03/2023, our NeuDA has been accepted to [CVPR 2023](https://cvpr2023.thecvf.com/).
- 07/2022, our HrSRG has been accepted to [ECCV 2022](https://eccv2022.ecva.net/).
- 03/2022, three papers have been accepted to [CVPR 2022](https://cvpr2022.thecvf.com/).
- 09/2021, our 3D-FUTURE paper has been accepted to [IJCV](https://www.springer.com/journal/11263). 
- 07/2021, our 3D-FRONT paper has been accepted to [ICCV 2021](http://iccv2021.thecvf.com/). 
- 12/2020, one paper has been accepted to [AAAI 2021](https://aaai.org/Conferences/AAAI-21/aaai21call/).
- 11/2020, one paper has been accepted to [TPAMI](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34).
- 10/2020, our 3D-FRONT (3D Furnished Rooms with layOuts and semaNTics) dataset has received the ChinaGraph Best Dataset Award.
- 09/2020, two papers have been accepted to [NeurlPS 2020](https://neurips.cc/Conferences/2020/).
- 06/2020, very happy to announce the release of 3D-FRONT (3D-FRONT: 3D Furnished Rooms with layOuts and semaNTics). [3D-FRONT](https://tianchi.aliyun.com/specials/promotion/alibaba-3d-scene-dataset) is a new large-scale 3D scene dataset containing 6,813 distinct houses and 19,775 diversely furnished rooms. 
- 04/2020, very happy to announce the release of 3D-FUTURE (3D-FUTURE: 3D FUrniture shape with TextURE
). [3D-FUTURE](https://tianchi.aliyun.com/specials/promotion/alibaba-3d-future) is a new large-scale 3D model dataset containing 9,992 high-quality 3D shapes with infomative textures.
- 03/2020, I am a co-organizer of the IJCAI 2020 workshop: [3D Artificial Intelligence Challenge through 3D-FUTURE Benchmark](https://tianchi.aliyun.com/specials/promotion/ijcai-alibaba-3d-future-workshop). Welcome to join us.
- 06/2019, our paper GcGAN has been selected as **Best Paper Finalist**, CVPR19. 
- 02/2019, two papers have been accepted to [CVPR 2019](https://cvpr2019.thecvf.com/). 
- 06/2018, our method [DORN](https://arxiv.org/abs/1806.02446) won the 1st prize in single image depth prediction competition in Robust Vision Challenge 2018.
- 02/2018, one paper has been accepted to [CVPR 2018](https://cvpr2018.thecvf.com/).

---

<a name="publication"></a>
### Publications
<sup>#</sup>: Corresponding Author

#### Conferences & Journals

><tt style="color:grey; font-size: 100%;">Multiscale Representation for Real-Time Anti-Aliasing Neural Rendering
</tt> <br/>
><tt style="color:black; font-size: 90%;">Accepted to ICCV, 2023</tt> <br/>
><tt style="color:black; font-size: 90%;">Dongting Hu, Zhenkai Zhang, Tingbo Hou, Tongliang Liu, </tt><tt style="color:red; font-size: 90%;">Huan Fu<sup>#</sup></tt><tt style="color:black; font-size: 90%;">, Mingming Gongg<sup>#</sup></tt> <br/>

><tt style="color:grey; font-size: 100%;">NeuDA: Neural Deformable Anchor for High-Fidelity Implicit Surface Reconstruction
</tt> <br/>
><tt style="color:black; font-size: 90%;">Accepted to CVPR, 2023</tt> <br/>
><tt style="color:black; font-size: 90%;">Bowen Cai, Jinchi Huang, Rongfei Jia, Chengfei Lv, </tt><tt style="color:red; font-size: 90%;">Huan Fu<sup>#</sup></tt><tt style="color:black; font-size: 90%;"></tt> <br/>

><tt style="color:grey; font-size: 100%;">Digging into Radiance Grid for Real-Time View Synthesis with Detail Preservation
</tt> <br/>
><tt style="color:black; font-size: 90%;">Accepted to ECCV, 2022</tt> <br/>
><tt style="color:black; font-size: 90%;">Jian Zhang<sup>*</sup>, Jinchi Huang<sup>*</sup>, Bowen Cai<sup>*</sup>, Mingming Gong, Chaohui Wang, Jiaming Wang, Hongchen Luo, Rongfei Jia, Binqiang Zhao, Xing Tang, </tt><tt style="color:red; font-size: 90%;">Huan Fu<sup>#</sup></tt><tt style="color:black; font-size: 90%;"></tt> <br/>

><tt style="color:grey; font-size: 100%;">Ray Priors through Reprojection: Improving Neural Radiance Fields for Novel View Extrapolation
</tt> <br/>
><tt style="color:black; font-size: 90%;">Accepted to CVPR, 2022</tt> <br/>
><tt style="color:black; font-size: 90%;">Jian Zhang<sup>*</sup>, Yuanqing Zhang<sup>*</sup>, </tt><tt style="color:red; font-size: 90%;">Huan Fu<sup>#</sup></tt><tt style="color:black; font-size: 90%;">, Xiaowei Zhou, Bowen Cai, Jinchi Huang, Rongfei Jia, Binqiang Zhao, and Xing Tang</tt> <br/>

><tt style="color:grey; font-size: 100%;">Modeling Indirect Illumination for Inverse Rendering
</tt> <br/>
><tt style="color:black; font-size: 90%;">Accepted to CVPR, 2022</tt> <br/>
><tt style="color:black; font-size: 90%;">Yuanqing Zhang, Jiaming Sun, Xingyi He, </tt><tt style="color:red; font-size: 90%;">Huan Fu</tt><tt style="color:black; font-size: 90%;">, Rongfei Jia, and Xiaowei Zhou</tt> <br/>

><tt style="color:grey; font-size: 100%;">Alleviating Semantics Distortion in Unsupervised Low-Level Image-to-Image Translation via Structure Consistency Constraint
</tt> <br/>
><tt style="color:black; font-size: 90%;">Accepted to CVPR, 2022</tt> <br/>
><tt style="color:black; font-size: 90%;">Jiaxian Guo, Jiachen Li, </tt><tt style="color:red; font-size: 90%;">Huan Fu</tt><tt style="color:black; font-size: 90%;">, Mingming Gong, Kun Zhang, and Dacheng Tao</tt> <br/>

><tt style="color:grey; font-size: 100%;">3D-FUTURE: 3D Furniture shape with TextURE
</tt> <br/>
><tt style="color:black; font-size: 90%;">Accepted to IJCV, 2021</tt> <br/>
><tt style="color:red; font-size: 90%;">Huan Fu</tt><tt style="color:black; font-size: 90%;">, Rongfei Jia, Lin Gao, Mingming Gong, Binqiang Zhao, Steve Maybank, and Dacheng Tao</tt> <br/>
>\[[paper](https://arxiv.org/abs/2009.09633)\]<br/>

><tt style="color:grey; font-size: 100%;">3D-FRONT: 3D Furnished Rooms with layOuts and semaNTics
</tt> <br/>
><tt style="color:black; font-size: 90%;">International Conference on Computer Vision (**ICCV**), 2021</tt> <br/>
><tt style="color:red; font-size: 90%;">Huan Fu</tt><tt style="color:black; font-size: 90%;">, Bowen Cai, Lin Gao, Lingxiao Zhang, Cao Li, Jiaming Wang, Qixun Zeng, Chengyue Sun, Rongfei Jia, Binqiang Zhao, and Hao Zhang</tt> <br/>
>\[[Project Page](https://tianchi.aliyun.com/specials/promotion/alibaba-3d-scene-dataset)\]<br/>

><tt style="color:grey; font-size: 100%;">Adaptive Context-Aware Multi-Modal Network for Depth Completions</tt> <br/>
><tt style="color:black; font-size: 90%;">IEEE Transaction on Image Processing (**T-IP**), 2021</tt> <br/>
><tt style="color:black; font-size: 90%;">Shanshan Zhao, Mingming Gong, </tt><tt style="color:red; font-size: 90%;">Huan Fu</tt><tt style="color:black; font-size: 90%;">, and Dacheng Tao</tt> <br/>
>\[[paper](https://arxiv.org/pdf/2008.10833.pdf)\] \[[code](https://github.com/sshan-zhao/ACMNet)\]<br/>

><tt style="color:grey; font-size: 100%;">Exploiting Diverse Characteristics and Adversarial Ambivalence for Domain Adaptive Segmentation</tt> <br/>
><tt style="color:black; font-size: 90%;">Thirty-Fifth AAAI Conference on Artificial Intelligence (**AAAI**), 2021 </tt> <br/>
><tt style="color:black; font-size: 90%;">Bowen Cai, </tt><tt style="color:red; font-size: 90%;">Huan Fu</tt><tt style="color:black; font-size: 90%;">, Rongfei Jia, Binqiang Zhao, Hua Li, and Yinghui Xu</tt> <br/>
>\[[paper](https://arxiv.org/pdf/2012.05608.pdf)\] <br/>

><tt style="color:grey; font-size: 100%;">Occlusion Boundary: A Formal Definition & Its Detection via Deep Exploration of Context</tt> <br/>
><tt style="color:black; font-size: 90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence (**TPAMI**), 2020 </tt> <br/>
><tt style="color:black; font-size: 90%;">Chaohui Wang<sup>*</sup>, </tt><tt style="color:red; font-size: 90%;">Huan Fu<sup>*</sup></tt><tt style="color:black; font-size: 90%;">, Dacheng Tao, and Michael J. Black</tt> <br/>
>\[[paper](https://ieeexplore.ieee.org/document/9264681/)\] <br/>

><tt style="color:grey; font-size: 100%;">Hard Example Generation by Texture Synthesis for Cross-domain Shape Similarity Learning</tt> <br/>
><tt style="color:black; font-size: 90%;">Thirty-fourth Conference on Neural Information Processing Systems (**NeurlPS**), 2020 </tt> <br/>
><tt style="color:red; font-size: 90%;">Huan Fu<sup>*</sup></tt><tt style="color:black; font-size: 90%;">, Shunming Li<sup>*</sup>, Rongfei Jia, Mingming Gong, Binqiang Zhao, and Dacheng Tao</tt> <br/>
>\[[paper](https://arxiv.org/abs/2010.12238)\] \[[code](https://github.com/3D-FRONT-FUTURE/IBSR-texture)\] <br/>

><tt style="color:grey; font-size: 100%;">Domain Generalization via Entropy Regularization</tt> <br/>
><tt style="color:black; font-size: 90%;">Thirty-fourth Conference on Neural Information Processing Systems (**NeurlPS**), 2020 </tt> <br/>
><tt style="color:black; font-size: 90%;">Shanshan Zhao, Mingming Gong, Tongliang Liu, </tt><tt style="color:red; font-size: 90%;">Huan Fu</tt><tt style="color:black; font-size: 90%;">, and Dacheng Tao</tt> <br/>
>\[[paper](https://papers.nips.cc/paper/2020/file/b98249b38337c5088bbc660d8f872d6a-Paper.pdf)\] \[[code](https://github.com/sshan-zhao/DG_via_ER)\] <br/>

><tt style="color:grey; font-size: 100%;">Geometry-Consistent Generative Adversarial Networks for One-sided Unsupervised Domain Mapping</tt> <br/>
><tt style="color:black; font-size: 90%;">IEEE Conference on Computer Vision and Pattern Recognition (**CVPR**), 2019 (**Best Paper Finalist**)</tt> <br/>
><tt style="color:red; font-size: 90%;">Huan Fu<sup>*</sup></tt><tt style="color:black; font-size: 90%;">, Mingming Gong<sup>*</sup>, Kayhan Batmanghelich, Kun Zhang, and Dacheng Tao</tt> <br/>
>\[[paper](https://arxiv.org/abs/1809.05852)\] \[[code](https://github.com/hufu6371/GcGAN)\] <br/>

><tt style="color:grey; font-size: 100%;">Geometry-Aware Symmetric Domain Adaptation for Monocular Depth Estimation</tt> <br/>
><tt style="color:black; font-size: 90%;">IEEE Conference on Computer Vision and Pattern Recognition (**CVPR**), 2019</tt> <br/>
><tt style="color:black; font-size: 90%;">Shanshan Zhao, </tt><tt style="color:red; font-size: 90%;">Huan Fu</tt><tt style="color:black; font-size: 90%;">, Mingming Gong, and Dacheng Tao</tt> <br/>
>\[[paper](https://arxiv.org/abs/1904.01870)\] \[[code](https://github.com/sshan-zhao/GASDA)\] <br/>

><tt style="color:grey; font-size: 100%;">Multi-scale Masked 3-D U-Net for Brain Tumor Segmentation</tt> <br/>
><tt style="color:black; font-size: 90%;">International Conference on Medical Image Computing and Computer Assisted Intervention Brainlesion Workshop (**BrainLes@MICCAI**), 2018</tt> <br/>
><tt style="color:black; font-size: 90%;">Yanwu Xu, Mingming Gong, </tt><tt style="color:red; font-size: 90%;">Huan Fu</tt><tt style="color:black; font-size: 90%;">, Dacheng Tao, Kun Zhang, and Kayhan Batmanghelich</tt> <br/>
>\[[paper](https://link.springer.com/chapter/10.1007/978-3-030-11726-9_20)\] \[[book](https://www.springer.com/gp/book/9783030117221)\]<br/>

><tt style="color:grey; font-size: 100%;">Deep Ordinal Regression Network for Monocular Depth Estimation</tt> <br/>
><tt style="color:black; font-size: 90%;">IEEE Conference on Computer Vision and Pattern Recognition (**CVPR**), 2018</tt> <br/>
><tt style="color:red; font-size: 90%;">Huan Fu</tt><tt style="color:black; font-size: 90%;">, Mingming Gong, Chaohui Wang, Kayhan Batmanghelich, and Dacheng Tao</tt> <br/>
<tt style="color:orange; font-size: 80%;">The 1st Prize in Single Image Depth Estimation in Robust Vision Challenge 2018</tt><br/>
>\[[paper](https://arxiv.org/abs/1806.02446)\] \[[code](https://github.com/hufu6371/DORN)\] \[[talk](https://www.youtube.com/watch?v=EbMGyJdw2R4)\] \[[KITTI leaderboard](http://www.cvlibs.net/datasets/kitti/eval_depth.php?benchmark=depth_prediction)\]<br/>

><tt style="color:grey; font-size: 100%;">MoE-SPNet: A Mixture-of-Experts Scene Parsing Network</tt> <br/>
><tt style="color:black; font-size: 90%;">Pattern Recognition (**PR**), 2018</tt> <br/>
><tt style="color:red; font-size: 90%;">Huan Fu</tt><tt style="color:black; font-size: 90%;">, Mingming Gong, Chaohui Wang, and Dacheng Tao</tt> <br/>
>\[[paper](https://arxiv.org/abs/1806.07049)\]<br/>

><tt style="color:grey; font-size: 100%;">Local Blur Mapping: Exploiting High-Level Semantics by Deep Neural Networks</tt> <br/>
><tt style="color:black; font-size: 90%;">IEEE Transaction on Image Processing (**T-IP**), 2018</tt> <br/>
><tt style="color:black; font-size: 90%;">Kede Ma, </tt><tt style="color:red; font-size: 90%;">Huan Fu</tt><tt style="color:black; font-size: 90%;">, Tongliang Liu, Zhou Wang, and Dacheng Tao</tt> <br/>
>\[[paper](https://arxiv.org/abs/1612.01227)\] \[[code](https://ece.uwaterloo.ca/~k29ma/)\]<br/>

><tt style="color:grey; font-size: 100%;">Occlusion Boundary Detection via Deep Exploration of Context</tt> <br/>
><tt style="color:black; font-size: 90%;">IEEE Conference on Computer Vision and Pattern Recognition (**CVPR**), 2016</tt> <br/>
><tt style="color:red; font-size: 90%;">Huan Fu</tt><tt style="color:black; font-size: 90%;">, Chaohui Wang, Dacheng Tao, and Michael J. Black</tt> <br/>
>\[[paper](http://files.is.tue.mpg.de/black/papers/FuCVPR2016.pdf)\]<br/>

><tt style="color:grey; font-size: 100%;">Facial Expression Recognition using Deep Boltzmann Machine from Thermal Infrared Images</tt> <br/>
><tt style="color:black; font-size: 90%;">Affective Computing and Intelligent Interaction (**ACII**), 2013</tt> <br/>
><tt style="color:black; font-size: 90%;">Shan He, Shangfei Wang, Wuwei Lan, </tt><tt style="color:red; font-size: 90%;">Huan Fu</tt><tt style="color:black; font-size: 90%;">, and Qiang Ji</tt> <br/>
>\[[paper](https://ieeexplore.ieee.org/document/6681437)\]<br/>

#### Preprints

><tt style="color:grey; font-size: 100%;">A Compromise Principle in Deep Monocular Depth Estimation</tt> <br/>
><tt style="color:black; font-size: 90%;">Tech. report, 2018</tt> <br/>
><tt style="color:red; font-size: 90%;">Huan Fu</tt><tt style="color:black; font-size: 90%;">, Mingming Gong, Chaohui Wang, and Dacheng Tao</tt> <br/>

---

<a name="experience"></a>
### Education & Experience
#### Education
<tt style="color:grey; font-size: 100%;">March 2017 - April 2019 (Ph.D.)</tt> <br/>
<tt style="color:black; font-size: 100%;">UBTECH Sydney AI Centre, School of Computer Science, Faculty of Engineering and Information Technologies (FEIT), University of Sydney (USYD), Australia</tt> <br/>
<tt style="color:teal; font-size: 100%;">**Supervisor:**</tt> Prof. Dacheng Tao<br/> 
<tt style="color:teal; font-size: 100%;">**Co-supervisor:**</tt> A/Prof. Chaohui Wang and A/Prof. Mingming Gong<br/>

<tt style="color:grey; font-size: 100%;">September 2014 - March 2017 (Ph.D. Student)</tt> <br/>
<tt style="color:black; font-size: 100%;">Faculty of Engineering and Information Technologies (FEIT), University of Technology Sydney (UTS), Australia</tt> <br/>
<tt style="color:teal; font-size: 100%;">**Supervisor:**</tt> Prof. Dacheng Tao <br/> 
<tt style="color:teal; font-size: 100%;">**Co-supervisor:**</tt> A/Prof. Chaohui Wang and A/Prof. Mingming Gong<br/>

<tt style="color:grey; font-size: 100%;">July 2014 - August 2010 (B.S.) </tt> <br/>
<tt style="color:black; font-size: 100%;">School of Information Science and Technology, University of Science and Technology of China (USTC), China</tt> <br/>
<tt style="color:teal; font-size: 100%;">**Supervisor:**</tt> A/Prof. Xinmei Tian and A/Prof. Shangfei Wang <br/>

#### Experience
<tt style="color:grey; font-size: 100%;">May 2019 - Present</tt> <br/>
<tt style="color:black; font-size: 100%;">Tao Technology Depertment, Alibaba Group, China</tt> <br/>

<tt style="color:grey; font-size: 100%;">July 2013 - October 2013 (Software Engineer Intern)</tt> <br/>
<tt style="color:black; font-size: 100%;">Microsoft Asia-Pacific R&D Group (ARD), China</tt> <br/>

---

<a name="service"></a>
### Services
#### Conference SPC member
- IJCAI21
- IJCAI23

#### Conference PC member
- CVPR23, ICML23, ICCV23, NeurIPS23
- NeurIPS22, 3DV22, ECCV22, CVPR22, ICML22, AAAI22, IJCAI22
- NeurIPS21, ICCV21, CVPR21, ICML21, AAAI21
- NeurIPS20, CVPR20, AAAI20, IJCAI20

#### Journal Reviewer
- IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)
- IEEE Transactions on Neural Networks and Learning Systems (T-NNLS)
- IEEE Transactions on Image Processing (T-IP)
- IEEE Transactions on Cybernetics (T-CYB)
- ACM Transactions on Knowledge Discovery from Data (T-KDD)
- Pattern Recognition (PR)

